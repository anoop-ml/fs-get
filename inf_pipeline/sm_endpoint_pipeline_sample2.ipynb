{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cbd730",
   "metadata": {},
   "source": [
    "### Example for inference pipeline using feature store fs get and xgboost container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13bcf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sm_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4eafa",
   "metadata": {},
   "source": [
    "Create a feature group and ingest a sample record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b10dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading feature group definition\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feat_cols = ['f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8','f_9']\n",
    "df = pd.DataFrame([[1, '2020-12-21T01:00:00Z', 0.0, 0.0, 0.335, 0.22, 0.07, 0.17, 0.076, 0.0365, 0.05]], \n",
    "             columns=['f_id', 'f_time'] + feat_cols)\n",
    "\n",
    "def cast_object_to_string(df):\n",
    "    for col in df.columns:\n",
    "        if df.dtypes[col] == 'object':\n",
    "            df[col] = df[col].astype('str').astype('string')\n",
    "            \n",
    "# cast object dtype to string. The SageMaker FeatureStore Python SDK will then map the string dtype to String feature type.\n",
    "cast_object_to_string(df)\n",
    "\n",
    "record_identifier_feature_name = \"f_id\"\n",
    "event_time_feature_name = \"f_time\"\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "timestamp_suffix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "fg_name = 'fg-'+ timestamp_suffix\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "fg = FeatureGroup(name=fg_name, sagemaker_session=sm_session)\n",
    "fg.load_feature_definitions(data_frame=df)\n",
    "print ('done loading feature group definition') # to supress previous call output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e39f1cd",
   "metadata": {},
   "source": [
    "Create and ingest into feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26bf62d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup fg-2021-06-15-01-49-35 successfully created.\n",
      "{'ResponseMetadata': {'RequestId': '6f20f5c6-13a4-4ba5-b788-6b9348dea3fd', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6f20f5c6-13a4-4ba5-b788-6b9348dea3fd', 'content-type': 'application/json', 'content-length': '419', 'date': 'Tue, 15 Jun 2021 01:49:51 GMT'}, 'RetryAttempts': 0}, 'Record': [{'FeatureName': 'f_1', 'ValueAsString': '0.0'}, {'FeatureName': 'f_2', 'ValueAsString': '0.0'}, {'FeatureName': 'f_3', 'ValueAsString': '0.335'}, {'FeatureName': 'f_4', 'ValueAsString': '0.22'}, {'FeatureName': 'f_5', 'ValueAsString': '0.07'}, {'FeatureName': 'f_6', 'ValueAsString': '0.17'}, {'FeatureName': 'f_7', 'ValueAsString': '0.076'}, {'FeatureName': 'f_8', 'ValueAsString': '0.0365'}, {'FeatureName': 'f_9', 'ValueAsString': '0.05'}]}\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "kwargs = dict(\n",
    "    s3_uri = False,\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=True\n",
    ")\n",
    "fg.create(**kwargs)\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(fg)\n",
    "\n",
    "fg.ingest(data_frame=df, wait=True)\n",
    "\n",
    "# verify feature get\n",
    "feature_record_id = str(1)\n",
    "record = sm_session.boto_session.client('sagemaker-featurestore-runtime', region_name=sm_session.boto_region_name) \\\n",
    "    .get_record(FeatureGroupName=fg_name, RecordIdentifierValueAsString=feature_record_id, FeatureNames=feat_cols)\n",
    "print (record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71c6da",
   "metadata": {},
   "source": [
    "Deploy a model, to interact with feature store. It can be the first step in a inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f9ac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference_fs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference_fs.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sagemaker\"])\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker_containers.beta.framework import (\n",
    "    encoders,\n",
    "    worker\n",
    ")\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "boto_fs_client = boto_session.client(service_name='sagemaker-featurestore-runtime')\n",
    "feat_cols = ['f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8','f_9']\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print ('processing - in model_fn')\n",
    "    return None\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print (f'processing - in input_fn with content_type = {request_content_type}')\n",
    "    return request_body\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    print ('processing - in predict_fn')\n",
    "    \n",
    "    params = input_data.split(',')\n",
    "    fg_name = params[0]\n",
    "    input_feat_id = int(params[1])\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    rec = boto_fs_client.get_record(FeatureGroupName=fg_name, RecordIdentifierValueAsString=str(input_feat_id),FeatureNames=feat_cols)\n",
    "    end = time.time()\n",
    "    feats = rec.get('Record', None)\n",
    "    duration = end-start\n",
    "    \n",
    "    print (f'processing - duration = {duration}')\n",
    "    \n",
    "    if feats:\n",
    "        return [','.join(i['ValueAsString'] for i in feats)]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#ref - https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/handler_service.py\n",
    "def output_fn(prediction, accept):\n",
    "    print (f'processing - output_fn with values = {prediction}, for output content_type = {accept}')\n",
    "    return worker.Response(encoders.encode(prediction, accept), mimetype=accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1cee40",
   "metadata": {},
   "source": [
    "Create models, deploy and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf76080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inference Model\n",
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "fs_inference_model = XGBoostModel(\n",
    "    model_data=None,\n",
    "    role=role,\n",
    "    entry_point=\"inference_fs.py\",\n",
    "    framework_version=\"1.2-2\",\n",
    "    sagemaker_session=sm_session\n",
    ")\n",
    "fs_inference_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bad7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference_xgb.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference_xgb.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from sagemaker_containers.beta.framework import encoders\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print ('processing - in model_fn')\n",
    "    return None\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print (f'processing - in input_fn with content_type = {request_content_type}, request_body = {request_body}')\n",
    "    return request_body\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    input_data_type = type(input_data)\n",
    "    print (f'processing - in predict_fn, with input_data = {input_data}, with type = {input_data_type}')\n",
    "    \n",
    "    return 100\n",
    "\n",
    "#ref - https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/handler_service.py\n",
    "def output_fn(prediction, accept):\n",
    "    print (f'processing - output_fn with values = {prediction}, for output content_type = {accept}')    \n",
    "    return str(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4283fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fake XGBoost model\n",
    "xgb_model = XGBoostModel(\n",
    "    model_data=None,\n",
    "    role=role,\n",
    "    entry_point=\"inference_xgb.py\",\n",
    "    framework_version=\"1.2-2\",\n",
    "    sagemaker_session=sm_session\n",
    ")\n",
    "xgb_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5aa583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "model_name = \"inference-pipeline-2\" + timestamp_suffix\n",
    "sm_model = PipelineModel(name=model_name, role=role, models=[fs_inference_model, xgb_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d645c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "\n",
    "endpoint_name = \"inference-pipeline-ep2-\" + timestamp_suffix\n",
    "endpoint_deploy = sm_model.deploy(initial_instance_count=1, \n",
    "                instance_type=\"ml.c4.xlarge\", \n",
    "                endpoint_name=endpoint_name,\n",
    "                serializer=CSVSerializer()\n",
    "#                deserializer=CSVDeserializer()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66da56aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'100'\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker.Session().sagemaker_runtime_client.invoke_endpoint( \n",
    "    EndpointName=endpoint_name,\n",
    "    Body=f'{fg_name}, {feature_record_id}',\n",
    "    ContentType=\"text/csv\",\n",
    "    Accept=\"text/csv\",\n",
    ")\n",
    "response_body = response['Body'] \n",
    "print(response_body.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a054af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'100'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import (\n",
    "    Predictor,\n",
    "    CSVSerializer,\n",
    "    CSVDeserializer\n",
    ")\n",
    "\n",
    "payload = f'{fg_name}, {feature_record_id}'\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=None,\n",
    "    serializer=CSVSerializer(),\n",
    "    Content_Type=\"text/csv\",\n",
    "    Accept=\"text/csv\"\n",
    ")\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21870820",
   "metadata": {},
   "source": [
    "Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63731be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete fg\n",
    "fg.delete()\n",
    "\n",
    "# delete endpoint\n",
    "sm_session.delete_endpoint(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495b893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
