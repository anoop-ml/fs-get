{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ba386a",
   "metadata": {},
   "source": [
    "### Example for inference pipeline using feature store fs get and xgboost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425a359",
   "metadata": {},
   "source": [
    "XGBoost model is based on https://github.com/aws/amazon-sagemaker-examples/tree/master/advanced_functionality/inference_pipeline_sparkml_xgboost_abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b12ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sm_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8fcc79",
   "metadata": {},
   "source": [
    "Create a feature group and ingest a sample record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feat_cols = ['f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8','f_9']\n",
    "df = pd.DataFrame([[1, '2020-12-21T01:00:00Z', 0.0, 0.0, 0.335, 0.22, 0.07, 0.17, 0.076, 0.0365, 0.05]], \n",
    "             columns=['f_id', 'f_time'] + feat_cols)\n",
    "\n",
    "def cast_object_to_string(df):\n",
    "    for col in df.columns:\n",
    "        if df.dtypes[col] == 'object':\n",
    "            df[col] = df[col].astype('str').astype('string')\n",
    "            \n",
    "# cast object dtype to string. The SageMaker FeatureStore Python SDK will then map the string dtype to String feature type.\n",
    "cast_object_to_string(df)\n",
    "\n",
    "record_identifier_feature_name = \"f_id\"\n",
    "event_time_feature_name = \"f_time\"\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "timestamp_suffix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "fg_name = 'fg-'+ timestamp_suffix\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "fg = FeatureGroup(name=fg_name, sagemaker_session=sm_session)\n",
    "fg.load_feature_definitions(data_frame=df)\n",
    "print ('done loading feature group definition') # to supress previous call output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f112a1e2",
   "metadata": {},
   "source": [
    "Create and ingest into feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d58601",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "kwargs = dict(\n",
    "    s3_uri = False,\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=True\n",
    ")\n",
    "fg.create(**kwargs)\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(fg)\n",
    "\n",
    "fg.ingest(data_frame=df, wait=True)\n",
    "\n",
    "# verify feature get\n",
    "feature_record_id = str(1)\n",
    "record = sm_session.boto_session.client('sagemaker-featurestore-runtime', region_name=sm_session.boto_region_name) \\\n",
    "    .get_record(FeatureGroupName=fg_name, RecordIdentifierValueAsString=feature_record_id, FeatureNames=feat_cols)\n",
    "print (record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2260b",
   "metadata": {},
   "source": [
    "Deploy a model, to interact with feature store. It can be the first step in a inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile inference_fs.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "#from sagemaker_inference import content_types\n",
    "#from sagemaker_containers.beta.framework import encoders\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sagemaker\"])\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "boto_fs_client = boto_session.client(service_name='sagemaker-featurestore-runtime')\n",
    "feat_cols = ['f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8','f_9']\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print ('processing - in model_fn')\n",
    "    return None\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print (f'processing - in input_fn with content_type = {request_content_type}')\n",
    "    return request_body\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    print ('processing - in predict_fn')\n",
    "    \n",
    "    params = input_data.split(',')\n",
    "    fg_name = params[0]\n",
    "    input_feat_id = int(params[1])\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    rec = boto_fs_client.get_record(FeatureGroupName=fg_name, RecordIdentifierValueAsString=str(input_feat_id),FeatureNames=feat_cols)\n",
    "    end = time.time()\n",
    "    feats = rec.get('Record', None)\n",
    "    duration = end-start\n",
    "    \n",
    "    print (f'processing - duration = {duration}')\n",
    "    \n",
    "    if feats:\n",
    "        return ','.join(i['ValueAsString'] for i in feats)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "#ref - https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/handler_service.py\n",
    "def output_fn(prediction, content_type):\n",
    "    print (f'processing - output_fn with values = {prediction}, for output content_type = {content_type}')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b7f3d",
   "metadata": {},
   "source": [
    "Create models, deploy and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inference Model\n",
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "fs_inference_model = XGBoostModel(\n",
    "    model_data=None,\n",
    "    role=role,\n",
    "    entry_point=\"inference_fs.py\",\n",
    "    framework_version=\"1.2-2\",\n",
    "    sagemaker_session=sm_session\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6210dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create xgboost model\n",
    "from sagemaker.model import Model\n",
    "model_tar = 's3://scratch-fs/xgboost_model_sample/model.tar.gz'\n",
    "image_uri = sagemaker.image_uris.retrieve(\"xgboost\", \"us-west-2\", \"latest\")\n",
    "xgb_model = Model(\n",
    "    model_data= model_tar, \n",
    "    image_uri=image_uri,\n",
    "    sagemaker_session=sm_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "model_name = \"inference-pipeline-\" + timestamp_suffix\n",
    "sm_model = PipelineModel(name=model_name, role=role, models=[fs_inference_model, xgb_model])\n",
    "#sm_model = PipelineModel(name=model_name, role=role, models=[fs_inference_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"inference-pipeline-ep-\" + timestamp_suffix\n",
    "sm_model.deploy(initial_instance_count=1, \n",
    "                instance_type=\"ml.c4.xlarge\", \n",
    "                endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72461e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker.Session().sagemaker_runtime_client.invoke_endpoint( \n",
    "    EndpointName=endpoint_name,\n",
    "    Body=f'{fg_name}, {feature_record_id}',\n",
    "    ContentType=\"text/csv\",\n",
    "    Accept=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_body = response['Body'] \n",
    "print(response_body.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b3cf94",
   "metadata": {},
   "source": [
    "Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a358e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete fg\n",
    "fg.delete()\n",
    "\n",
    "# delete endpoint\n",
    "sm_session.delete_endpoint(endpoint_name=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
