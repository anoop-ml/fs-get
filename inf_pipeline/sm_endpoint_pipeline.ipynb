{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab61a7f6",
   "metadata": {},
   "source": [
    "### Example for inference pipeline using feature store fs get and xgboost container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sm_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe0b14",
   "metadata": {},
   "source": [
    "Create a feature group and ingest a sample record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f13ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feat_cols = ['f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8','f_9']\n",
    "df = pd.DataFrame([[1, '2020-12-21T01:00:00Z', 0.0, 0.0, 0.335, 0.22, 0.07, 0.17, 0.076, 0.0365, 0.05]], \n",
    "             columns=['f_id', 'f_time'] + feat_cols)\n",
    "\n",
    "def cast_object_to_string(df):\n",
    "    for col in df.columns:\n",
    "        if df.dtypes[col] == 'object':\n",
    "            df[col] = df[col].astype('str').astype('string')\n",
    "            \n",
    "# cast object dtype to string. The SageMaker FeatureStore Python SDK will then map the string dtype to String feature type.\n",
    "cast_object_to_string(df)\n",
    "\n",
    "record_identifier_feature_name = \"f_id\"\n",
    "event_time_feature_name = \"f_time\"\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "timestamp_suffix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "fg_name = 'fg-'+ timestamp_suffix\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "fg = FeatureGroup(name=fg_name, sagemaker_session=sm_session)\n",
    "fg.load_feature_definitions(data_frame=df)\n",
    "print ('done loading feature group definition') # to supress previous call output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed666113",
   "metadata": {},
   "source": [
    "Create and ingest into feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(\n",
    "    s3_uri = False,\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=True\n",
    ")\n",
    "fg.create(**kwargs)\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(fg)\n",
    "\n",
    "fg.ingest(data_frame=df, wait=True)\n",
    "\n",
    "# verify feature get\n",
    "feature_record_id = str(1)\n",
    "record = sm_session.boto_session.client('sagemaker-featurestore-runtime', region_name=sm_session.boto_region_name) \\\n",
    "    .get_record(FeatureGroupName=fg_name, RecordIdentifierValueAsString=feature_record_id, FeatureNames=feat_cols)\n",
    "print (record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db8ddc",
   "metadata": {},
   "source": [
    "Deploy a model, to interact with feature store. It can be the first step in a inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01991055",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile inference_fs.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sagemaker\"])\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker_containers.beta.framework import (\n",
    "    encoders,\n",
    "    worker\n",
    ")\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "boto_fs_client = boto_session.client(service_name='sagemaker-featurestore-runtime')\n",
    "feat_cols = ['f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8','f_9']\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print ('processing - in model_fn')\n",
    "    return None\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print (f'processing - in input_fn with content_type = {request_content_type}')\n",
    "    return request_body\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    print ('processing - in predict_fn')\n",
    "    \n",
    "    params = input_data.split(',')\n",
    "    fg_name = params[0]\n",
    "    input_feat_id = int(params[1])\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    rec = boto_fs_client.get_record(FeatureGroupName=fg_name, RecordIdentifierValueAsString=str(input_feat_id),FeatureNames=feat_cols)\n",
    "    end = time.time()\n",
    "    feats = rec.get('Record', None)\n",
    "    duration = end-start\n",
    "    \n",
    "    print (f'processing - duration = {duration}')\n",
    "    \n",
    "    if feats:\n",
    "        return [','.join(i['ValueAsString'] for i in feats)]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#ref - https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/handler_service.py\n",
    "def output_fn(prediction, accept):\n",
    "    print (f'processing - output_fn with values = {prediction}, for output content_type = {accept}')\n",
    "    return worker.Response(encoders.encode(prediction, accept), mimetype=accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf36d2c",
   "metadata": {},
   "source": [
    "Create models, deploy and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9887c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inference Model\n",
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "fs_inference_model = XGBoostModel(\n",
    "    model_data=None,\n",
    "    role=role,\n",
    "    entry_point=\"inference_fs.py\",\n",
    "    framework_version=\"1.2-2\",\n",
    "    sagemaker_session=sm_session\n",
    ")\n",
    "fs_inference_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da92683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile inference_xgb.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from sagemaker_containers.beta.framework import encoders\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print ('processing - in model_fn')\n",
    "    return None\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print (f'processing - in input_fn with content_type = {request_content_type}, request_body = {request_body}')\n",
    "    return request_body\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    input_data_type = type(input_data)\n",
    "    print (f'processing - in predict_fn, with input_data = {input_data}, with type = {input_data_type}')\n",
    "    \n",
    "    return 100\n",
    "\n",
    "#ref - https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/handler_service.py\n",
    "def output_fn(prediction, accept):\n",
    "    print (f'processing - output_fn with values = {prediction}, for output content_type = {accept}')    \n",
    "    return str(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBoostModel(\n",
    "    model_data=None,\n",
    "    role=role,\n",
    "    entry_point=\"inference_xgb.py\",\n",
    "    framework_version=\"1.2-2\",\n",
    "    sagemaker_session=sm_session\n",
    ")\n",
    "xgb_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "model_name = \"inference-pipeline-2\" + timestamp_suffix\n",
    "sm_model = PipelineModel(name=model_name, role=role, models=[fs_inference_model, xgb_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb433b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "\n",
    "endpoint_name = \"inference-pipeline-ep2-\" + timestamp_suffix\n",
    "endpoint_deploy = sm_model.deploy(initial_instance_count=1, \n",
    "                instance_type=\"ml.c4.xlarge\", \n",
    "                endpoint_name=endpoint_name,\n",
    "                serializer=CSVSerializer()\n",
    "#                deserializer=CSVDeserializer()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker.Session().sagemaker_runtime_client.invoke_endpoint( \n",
    "    EndpointName=endpoint_name,\n",
    "    Body=f'{fg_name}, {feature_record_id}',\n",
    "    ContentType=\"text/csv\",\n",
    "    Accept=\"text/csv\",\n",
    ")\n",
    "response_body = response['Body'] \n",
    "print(response_body.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a54681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import (\n",
    "    Predictor,\n",
    "    CSVSerializer,\n",
    "    CSVDeserializer\n",
    ")\n",
    "\n",
    "payload = f'{fg_name}, {feature_record_id}'\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=None,\n",
    "    serializer=CSVSerializer(),\n",
    "    Content_Type=\"text/csv\",\n",
    "    Accept=\"text/csv\"\n",
    ")\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bb5b1",
   "metadata": {},
   "source": [
    "Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete fg\n",
    "fg.delete()\n",
    "\n",
    "# delete endpoint\n",
    "sm_session.delete_endpoint(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0a8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
