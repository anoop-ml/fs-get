{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ebf7c3",
   "metadata": {},
   "source": [
    "### Example for inference pipeline using feature store fs get and xgboost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d32d37",
   "metadata": {},
   "source": [
    "XGBoost model is based on https://github.com/aws/amazon-sagemaker-examples/tree/master/advanced_functionality/inference_pipeline_sparkml_xgboost_abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba902054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sm_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02aaa49",
   "metadata": {},
   "source": [
    "Create a feature group and ingest a sample record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac239e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading feature group definition\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feat_cols = ['f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8','f_9']\n",
    "df = pd.DataFrame([[1, '2020-12-21T01:00:00Z', 0.0, 0.0, 0.335, 0.22, 0.07, 0.17, 0.076, 0.0365, 0.05]], \n",
    "             columns=['f_id', 'f_time'] + feat_cols)\n",
    "\n",
    "def cast_object_to_string(df):\n",
    "    for col in df.columns:\n",
    "        if df.dtypes[col] == 'object':\n",
    "            df[col] = df[col].astype('str').astype('string')\n",
    "            \n",
    "# cast object dtype to string. The SageMaker FeatureStore Python SDK will then map the string dtype to String feature type.\n",
    "cast_object_to_string(df)\n",
    "\n",
    "record_identifier_feature_name = \"f_id\"\n",
    "event_time_feature_name = \"f_time\"\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import time\n",
    "timestamp_suffix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "fg_name = 'fg-'+ timestamp_suffix\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "fg = FeatureGroup(name=fg_name, sagemaker_session=sm_session)\n",
    "fg.load_feature_definitions(data_frame=df)\n",
    "print ('done loading feature group definition') # to supress previous call output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c33384",
   "metadata": {},
   "source": [
    "Create and ingest into feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa9c486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup fg-2021-06-15-02-45-41 successfully created.\n",
      "{'ResponseMetadata': {'RequestId': '763e6688-a780-468e-9f31-230842c2ad47', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '763e6688-a780-468e-9f31-230842c2ad47', 'content-type': 'application/json', 'content-length': '419', 'date': 'Tue, 15 Jun 2021 02:46:00 GMT'}, 'RetryAttempts': 0}, 'Record': [{'FeatureName': 'f_1', 'ValueAsString': '0.0'}, {'FeatureName': 'f_2', 'ValueAsString': '0.0'}, {'FeatureName': 'f_3', 'ValueAsString': '0.335'}, {'FeatureName': 'f_4', 'ValueAsString': '0.22'}, {'FeatureName': 'f_5', 'ValueAsString': '0.07'}, {'FeatureName': 'f_6', 'ValueAsString': '0.17'}, {'FeatureName': 'f_7', 'ValueAsString': '0.076'}, {'FeatureName': 'f_8', 'ValueAsString': '0.0365'}, {'FeatureName': 'f_9', 'ValueAsString': '0.05'}]}\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(\n",
    "    s3_uri = False,\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=True\n",
    ")\n",
    "fg.create(**kwargs)\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(fg)\n",
    "\n",
    "fg.ingest(data_frame=df, wait=True)\n",
    "\n",
    "# verify feature get\n",
    "feature_record_id = str(1)\n",
    "record = sm_session.boto_session.client('sagemaker-featurestore-runtime', region_name=sm_session.boto_region_name) \\\n",
    "    .get_record(FeatureGroupName=fg_name, RecordIdentifierValueAsString=feature_record_id, FeatureNames=feat_cols)\n",
    "print (record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1694a23",
   "metadata": {},
   "source": [
    "Deploy a model, to interact with feature store. It can be the first step in a inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee744bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile inference_fs.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sagemaker\"])\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker_containers.beta.framework import (\n",
    "    encoders,\n",
    "    worker\n",
    ")\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "boto_fs_client = boto_session.client(service_name='sagemaker-featurestore-runtime')\n",
    "feat_cols = ['f_1','f_2','f_3','f_4','f_5','f_6','f_7','f_8','f_9']\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print ('processing - in model_fn')\n",
    "    return None\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    print (f'processing - in input_fn with content_type = {request_content_type}')\n",
    "    return request_body\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    print ('processing - in predict_fn')\n",
    "    \n",
    "    params = input_data.split(',')\n",
    "    fg_name = params[0]\n",
    "    input_feat_id = int(params[1])\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    rec = boto_fs_client.get_record(FeatureGroupName=fg_name, RecordIdentifierValueAsString=str(input_feat_id),FeatureNames=feat_cols)\n",
    "    end = time.time()\n",
    "    feats = rec.get('Record', None)\n",
    "    duration = end-start\n",
    "    \n",
    "    print (f'processing - duration = {duration}')\n",
    "    \n",
    "    if feats:\n",
    "        return [','.join(i['ValueAsString'] for i in feats)]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#ref - https://github.com/aws/sagemaker-xgboost-container/blob/master/src/sagemaker_xgboost_container/handler_service.py\n",
    "def output_fn(prediction, accept):\n",
    "    print (f'processing - output_fn with values = {prediction}, for output content_type = {accept}')\n",
    "    return worker.Response(encoders.encode(prediction, accept), mimetype=accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da3c73",
   "metadata": {},
   "source": [
    "Create models, deploy and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f591e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Inference Model\n",
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "fs_inference_model = XGBoostModel(\n",
    "    model_data=None,\n",
    "    role=role,\n",
    "    entry_point=\"inference_fs.py\",\n",
    "    framework_version=\"1.2-2\",\n",
    "    sagemaker_session=sm_session\n",
    ")\n",
    "fs_inference_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d989286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create xgboost model\n",
    "from sagemaker.model import Model\n",
    "model_tar = 's3://scratch-fs/xgboost_model_sample/model.tar.gz'\n",
    "image_uri = sagemaker.image_uris.retrieve(\"xgboost\", \"us-west-2\", \"latest\")\n",
    "xgb_model = Model(\n",
    "    model_data= model_tar, \n",
    "    image_uri=image_uri,\n",
    "    sagemaker_session=sm_session)\n",
    "xgb_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9b41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "model_name = \"inference-pipeline-\" + timestamp_suffix\n",
    "sm_model = PipelineModel(name=model_name, role=role, models=[fs_inference_model, xgb_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc0b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "\n",
    "endpoint_name = \"inference-pipeline-ep-\" + timestamp_suffix\n",
    "endpoint_deploy = sm_model.deploy(initial_instance_count=1, \n",
    "                instance_type=\"ml.c4.xlarge\", \n",
    "                endpoint_name=endpoint_name,\n",
    "                serializer=CSVSerializer()\n",
    "#                deserializer=CSVDeserializer()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95579dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker.Session().sagemaker_runtime_client.invoke_endpoint( \n",
    "    EndpointName=endpoint_name,\n",
    "    Body=f'{fg_name}, {feature_record_id}',\n",
    "    ContentType=\"text/csv\",\n",
    "    Accept=\"text/csv\",\n",
    ")\n",
    "response_body = response['Body'] \n",
    "print(response_body.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd323732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import (\n",
    "    Predictor,\n",
    "    CSVSerializer,\n",
    "    CSVDeserializer\n",
    ")\n",
    "\n",
    "payload = f'{fg_name}, {feature_record_id}'\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=None,\n",
    "    serializer=CSVSerializer(),\n",
    "    Content_Type=\"text/csv\",\n",
    "    Accept=\"text/csv\"\n",
    ")\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2db0df",
   "metadata": {},
   "source": [
    "Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete fg\n",
    "fg.delete()\n",
    "\n",
    "# delete endpoint\n",
    "sm_session.delete_endpoint(endpoint_name=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
